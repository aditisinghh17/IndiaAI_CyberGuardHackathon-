{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a037905e-47ed-41b8-b76d-92e316b39169",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d2ceb70-004f-483c-bb7d-8cd57abebf50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>crimeaditionalinfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Online and Social Media Related Crime</td>\n",
       "      <td>Cyber Bullying  Stalking  Sexting</td>\n",
       "      <td>I had continue received random calls and abusi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Online Financial Fraud</td>\n",
       "      <td>Fraud CallVishing</td>\n",
       "      <td>The above fraudster is continuously messaging ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Online Gambling  Betting</td>\n",
       "      <td>Online Gambling  Betting</td>\n",
       "      <td>He is acting like a police and demanding for m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Online and Social Media Related Crime</td>\n",
       "      <td>Online Job Fraud</td>\n",
       "      <td>In apna Job I have applied for job interview f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Online Financial Fraud</td>\n",
       "      <td>Fraud CallVishing</td>\n",
       "      <td>I received a call from lady stating that she w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Online Financial Fraud</td>\n",
       "      <td>Fraud CallVishing</td>\n",
       "      <td>\\r\\n      n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Online Financial Fraud</td>\n",
       "      <td>Internet Banking Related Fraud</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Online Financial Fraud</td>\n",
       "      <td>UPI Related Frauds</td>\n",
       "      <td>FRAUD THROUGH  UPI FRAUDPHONE PE\\r\\nBANK NAME ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>RapeGang Rape RGRSexually Abusive Content</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Respected Sir\\r\\n\\r\\nA very serious matter I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Online Financial Fraud</td>\n",
       "      <td>DebitCredit Card FraudSim Swap Fraud</td>\n",
       "      <td>Identity theft   Fake Customer Care Service Fr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     category  \\\n",
       "0       Online and Social Media Related Crime   \n",
       "1                      Online Financial Fraud   \n",
       "2                    Online Gambling  Betting   \n",
       "3       Online and Social Media Related Crime   \n",
       "4                      Online Financial Fraud   \n",
       "..                                        ...   \n",
       "95                     Online Financial Fraud   \n",
       "96                     Online Financial Fraud   \n",
       "97                     Online Financial Fraud   \n",
       "98  RapeGang Rape RGRSexually Abusive Content   \n",
       "99                     Online Financial Fraud   \n",
       "\n",
       "                            sub_category  \\\n",
       "0      Cyber Bullying  Stalking  Sexting   \n",
       "1                      Fraud CallVishing   \n",
       "2               Online Gambling  Betting   \n",
       "3                       Online Job Fraud   \n",
       "4                      Fraud CallVishing   \n",
       "..                                   ...   \n",
       "95                     Fraud CallVishing   \n",
       "96        Internet Banking Related Fraud   \n",
       "97                    UPI Related Frauds   \n",
       "98                                   NaN   \n",
       "99  DebitCredit Card FraudSim Swap Fraud   \n",
       "\n",
       "                                   crimeaditionalinfo  \n",
       "0   I had continue received random calls and abusi...  \n",
       "1   The above fraudster is continuously messaging ...  \n",
       "2   He is acting like a police and demanding for m...  \n",
       "3   In apna Job I have applied for job interview f...  \n",
       "4   I received a call from lady stating that she w...  \n",
       "..                                                ...  \n",
       "95                                     \\r\\n      n...  \n",
       "96                                                     \n",
       "97  FRAUD THROUGH  UPI FRAUDPHONE PE\\r\\nBANK NAME ...  \n",
       "98  Respected Sir\\r\\n\\r\\nA very serious matter I w...  \n",
       "99  Identity theft   Fake Customer Care Service Fr...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds=pd.read_csv(\"C:/Users/Asus/Downloads/cyberai/train.csv\")\n",
    "ds.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "004d2a0f-babf-41ba-8f36-15461bb39be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5406134-912b-4888-8ee8-5c3d36f5e3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test datasets\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Combine text features\n",
    "train_data[\"text\"] = train_data[\"sub_category\"] + \" \" + train_data[\"crimeaditionalinfo\"]\n",
    "test_data[\"text\"] = test_data[\"sub_category\"] + \" \" + test_data[\"crimeaditionalinfo\"]\n",
    "\n",
    "# Encode labels\n",
    "train_data[\"label\"] = train_data[\"category\"].astype(\"category\").cat.codes\n",
    "test_data[\"label\"] = test_data[\"category\"].astype(\"category\").cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7415f212-1e3e-4cf7-8e7d-7ade9d934eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6612\n",
      "2242\n"
     ]
    }
   ],
   "source": [
    "print(train_data[\"text\"].isnull().sum())  # Check for NaN values\n",
    "print(test_data[\"text\"].isnull().sum())  # Check for NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7d59731-dccd-4f69-aef4-e287ee779652",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"text\"] = train_data[\"text\"].fillna(\"\").astype(str)\n",
    "test_data[\"text\"] = test_data[\"text\"].fillna(\"\").astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b235bbaf-bd67-4020-8cac-d558e8d58c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dbe2947-ce82-428b-bad2-429cad0170be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(list(train_data[\"text\"]), truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(list(test_data[\"text\"]), truncation=True, padding=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "217819c7-1cae-4a80-bcee-fa598e57f14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "train_dataset = TextDataset(train_encodings, list(train_data[\"label\"]))\n",
    "test_dataset = TextDataset(test_encodings, list(test_data[\"label\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37a2799c-8866-4cc9-9299-69ad8a102a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed82a380b7634efd972c15f2e9cc267f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "wandb: Currently logged in as: jainrivamait (jainrivamait-brightchamps). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Asus\\Downloads\\cyberai\\wandb\\run-20241122_154259-1vx27m58</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jainrivamait-brightchamps/huggingface/runs/1vx27m58' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/jainrivamait-brightchamps/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jainrivamait-brightchamps/huggingface' target=\"_blank\">https://wandb.ai/jainrivamait-brightchamps/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jainrivamait-brightchamps/huggingface/runs/1vx27m58' target=\"_blank\">https://wandb.ai/jainrivamait-brightchamps/huggingface/runs/1vx27m58</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17568' max='17568' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17568/17568 7:10:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>11.322732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.083600</td>\n",
       "      <td>11.408836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.104800</td>\n",
       "      <td>12.338241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=17568, training_loss=0.10774210107619644, metrics={'train_runtime': 25846.0529, 'train_samples_per_second': 10.874, 'train_steps_per_second': 0.68, 'total_flos': 1.848952462722509e+16, 'train_loss': 0.10774210107619644, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Load pre-trained BERT model with classification head\n",
    "num_classes = len(train_data[\"category\"].unique())\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_classes)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "# Trainer API\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "801a6649-f251-488d-b36a-3860fc49a4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Get predictions\n",
    "preds_output = trainer.predict(test_dataset)\n",
    "preds = torch.argmax(torch.tensor(preds_output.predictions), axis=1)\n",
    "\n",
    "# Ground truth labels\n",
    "true_labels = list(test_data[\"label\"])\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(true_labels, preds)\n",
    "\n",
    "# Precision and Recall (macro-averaged for multi-class tasks)\n",
    "precision = precision_score(true_labels, preds, average=\"macro\")\n",
    "recall = recall_score(true_labels, preds, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da1e0366-83e3-47d2-958f-f771329a4e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score=(2*precision*recall)/(precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0dd9e298-dab5-4265-baa3-dd42c72f1ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision (Macro): 0.67\n",
      "Recall (Macro): 0.71\n",
      "F1-Score:0.69\n"
     ]
    }
   ],
   "source": [
    "# Print metrics\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision (Macro): {precision:.4f}\")\n",
    "print(f\"Recall (Macro): {recall:.4f}\")\n",
    "print(f\"F1-Score:{f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41f1c061-7c06-45b7-b2f5-781781b679db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(input_text, model, tokenizer, label_map):\n",
    "    \"\"\"\n",
    "    Predict the category of the given text.\n",
    "    \n",
    "    Args:\n",
    "        input_text (str): The input text to classify.\n",
    "        model: The fine-tuned BERT model.\n",
    "        tokenizer: The tokenizer used for BERT.\n",
    "        label_map (dict): A dictionary mapping label indices to category names.\n",
    "    \n",
    "    Returns:\n",
    "        str: Predicted category.\n",
    "    \"\"\"\n",
    "    # Tokenize input text\n",
    "    encodings = tokenizer(input_text, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encodings)\n",
    "        predicted_label = torch.argmax(outputs.logits, dim=1).item()\n",
    "    \n",
    "    # Return the corresponding category\n",
    "    return label_map[predicted_label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dfd1c352-6e26-4826-aeb6-035b8dd21453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map label indices to category names\n",
    "label_map = {idx: label for idx, label in enumerate(train_data[\"category\"].astype(\"category\").cat.categories)}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
